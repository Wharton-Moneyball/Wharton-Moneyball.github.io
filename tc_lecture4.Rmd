---
title: "Lecture 4: Defining custom functions and standardizing data"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = TRUE, fig.align = "center")
library(tidyverse)
```

## Introduction

On day 3 of the morning lectures (Lecture 6), you see a graph of Earned Run Average (ERA) against year, along with a line connecting the average ERA in each year.

![](figures/lecture3_era.png)

In order to reproduce this image, we will work with the [Lahman Baseball Database](http://www.seanlahman.com/baseball-database.html). As it turns out, there is an R package that includes the entire database (up until the 2018 season). We will load that into R along with the `tidyverse` packages when we begin our analysis. 


## The Lahman Baseball Database

As mentioned above, we will use data from a baseball data maintained by [Sean Lahman](http://www.seanlahman.com). This database contains pitching, hitting, and fielding statistics from Major League Baseball from 1871 to 2016. The data is available as an R package, which we will need to install and load. To install the package, we need to run the following in our console.

```{r install Lahman, eval = FALSE}
install.packages("Lahman")
```

Once the package is installed, we can load it into R along with the tidyverse packages:

```{r load Lahman}
library(tidyverse)
library(Lahman)
```

As we know, many packages not only contain new functions, but also new datasets. Whenever we load a package, the datasets that are part of the package get implicitly loaded into the background. To see which datasets come with the Lahman package, we use the `data()` function. 

```{r Lahman datasets, eval=FALSE}
data(package = "Lahman")
```

This will open up a new window with all of the names of the datasets contained in the Lahman package. Today, we will specifically be focusing on the dataset called `Pitching`, which contains season-level statistics on all pitchers going all the way back to 1871. Let's load this dataset as a tibble (which is easier to read than the default data.frame) called `pitching`.

```{r load print pitching}
pitching <- as_tibble(Pitching)
pitching
```

There are tons of rows and columns in the dataset. For this exercise, we will only want to focus on ERA and also focus only on those pitchers who have pitched at least 150 innings. Unfortunately, the Lahman pitching dataset does not contain the number of innings pitched (IP). Instead, it has a column called "IPouts", which is the number of outs pitched and whose formula is $\text{IPOuts} = 3 \times \text{IP}.$

Using the pipe and the dplyr verbs we learned in [Lecture 2](lecture2.html), we will create a new dataset called `pitching` (we make it all lowercase to differentiate from the original Lahman `Pitching` dataset), then add the "IP" column, filter the data to include only all players who pitched at least 150 innings and played in either the AL or the NL, and select only the columns corresponding to the player, year, team, league, innings pitched, and ERA.

```{r pitching}
pitching <- pitching %>%
  mutate(IP = IPouts/3) %>% 
  filter(lgID %in% c('AL', 'NL') & IP >= 150) %>%
  select(playerID, yearID, teamID, lgID, IP, ERA)
pitching
```

**IMPORTANT**: Before reading any further, make sure you and your team understand completely what is happening in the code above.

Now that we have ERA for all pitchers eligible for our analysis, we can plot the ERAs by year.

```{r plot ERAs year}
ggplot(data = pitching) + 
  ylim(0, 10) + 
  geom_point(mapping = aes(x = yearID, y = ERA), size = 0.3)
```

Looking at the plot, it appears that some of the pitchers from the first few decades of baseball had the lowest ERA. Using `arrange()`, we can see which pitcher had the best season according to ERA. 

```{r arrange ERA}
arrange(pitching, ERA)
```

It would appear that the best pitching season of all time was [Dutch Leonard's](https://en.wikipedia.org/wiki/Dutch_Leonard_(left-handed_pitcher)) 1914 season with the Red Sox. The next best was [Mordecai Brown](https://en.wikipedia.org/wiki/Mordecai_Brown)'s 1906 season with the Cubs. How much better was Leonard's 0.96 ERA than Brown's 1.04 ERA?

To answer this, we can transform ERA to standardized units using the `mutate()` function. There is a minor complication: there is not a built-in function for standardizing a variable in R! Luckily for us, R allows us to define our own functions like so:

```{r standardize function}
standardize <- function(x){
  mu <- mean(x, na.rm = TRUE)
  sigma <- sd(x, na.rm = TRUE)
  return( (x - mu)/sigma )
}
```

For now, don't worry too much about the syntax or the `na.rm = TRUE` bits; we will discuss them in more depth later. Armed with our `standardize()` function, we can add a column called zERA_all which transforms ERA to the standardized scale.

```{r mutate zERA}
pitching <-
  pitching %>%
  mutate(zERA_all = standardize(ERA))
pitching %>% arrange(zERA_all)
```

Now we see that Leonard's 0.96 ERA was about 3 standard deviations below the overall mean of qualified pitchers, while Brown's was about 2.91 standard deviations below the mean. On the other hand, the ostensibly worst pitching season was Philadelphia's own [Les Sweetland](https://en.wikipedia.org/wiki/Les_Sweetland) in 1930. Incidentally enough, Sweetland started that season with a three-hit shutout! Check out this [ESPN blog post](http://www.espn.com/blog/sweetspot/post/_/id/48687/the-amazing-1930-philadelphia-phillies) about the 1930's Phillies pitching staff.

Of course, you might argue that comparing the raw ERAs across the various years is somewhat unfair. After all, the game as it was played in 1914 is very different to the one played today!  As such, it may be more appropriate to standardize all of the ERAs within each season separately. To do this, we will have to compute the mean and standard deviation of ERAs within each season.


## Grouped calculations

Very often in a data analysis, instead of performing a calculation on the entire data set, you'll want to first *split* the data into smaller subsets, *apply* the same calculation on every subset, and then *combine* the results from each subset. For example, in order to replicate the figure above from Prof. Wyner's lecture, we need to split our pitching dataset based on the year, compute the average ERA within each year, and then combine these into a single tibble.

One strength of dplyr is the ease with which you can follow this "split-apply-combine" paradigm using the function `group_by()`. We can use this in concert with the pipe as follows:

```{r group_by}
pitching <- pitching %>% 
  group_by(yearID)
```

When we print out `pitching` now, we notice an extra line that tells us the grouping variable. Now when we pass this dataset on to subsequent calculations, these calculations will be done on each group. 

We can now summarize each season using another `tidyverse` function called... `reframe()`! This convenient function will compute summary statistics that we specify with respect to the groups from `group_by()`. For instance, we can compute the average ERA in each year in the following way:

```{r summarize mean}
pitching %>%
  reframe(ave_ERA = mean(ERA))
```

The following functions are quite useful for summarizing several aspects of the distribution of the variables in our dataset:

* Center: `mean()`, `median()`
* Spread: `sd()`, `IQR()`
* Range: `min()`, `max()`
* Count: `n()`, `n_distinct()`

We'll now create a dataset, `pitching_summary`, that contains the mean and standard deviation of ERA **within each year**:

```{r summarize mean sd}
pitching_summary <- pitching %>% 
  reframe(mean = mean(ERA), 
            sd = sd(ERA))
```

One of the most commonly used functions, `n()`, returns counts and is especially useful when used on a grouped dataset We can, for instance, count the number of pitchers in our dataset within each year using `n()`.

```{r arrange}
pitching %>% 
  reframe(count = n()) %>%
  arrange(count)
```

Or equivalently, we can use the `count` function:

```{r count}
pitching %>% 
  count() %>%
  arrange(n)
```

What's the difference between the two approaches above?

**Exercise**: Describe, in words, what the following code does.

```{r exercise, eval = FALSE}
pitching %>% 
  reframe(count = n()) %>%
  filter(count >= 90) %>%
  arrange(desc(count))
```

Once we add a grouping to our dataset, it also changes the way `mutate()` operates on it. We can now standardize each pitcher's ERA within each year and store that result in a column called z_era_year.

```{r standardize ERA year}
pitching <- pitching %>%
  mutate(z_era_year = standardize(ERA))
pitching %>% arrange(z_era_year)
```


### Ungrouping and grouping on multiple variables

As we just saw, when we add a grouping to a dataset, it affects how verbs like `reframe()` and `mutate()` operate on our data. It is sometimes the case that we wish to remove the grouping and let these verbs (and others) operate on the entire dataset again.
To remove the grouping, we have to use the `ungroup()` function.
Remember, as with the other `tidyverse` verbs we've learned, we need to store the result if we want the dataset to remain ungrouped!

```{r ungroup}
pitching <- pitching %>%
  ungroup()
```

To verify that we've indeed removed the grouping, let's re-run the code from above to compute the mean and standard deviation of ERA.

```{r rerun ungrouped}
pitching %>% reframe(mean = mean(ERA), sd = sd(ERA))
```

Up to this point, we have only grouped on a single variable. It is sometimes desirable to group on multiple variables at once. For instance, we may want to standardize ERA not only within each year but also within each leauge (AL and NL). That is, we may want to standardize each individual pitcher's ERA using only the data from the other pitchers who pitched in the same league and in the same season. We also add a column called `count_year_lg` to record the number of pitchers included in each year-league combination.

```{r group multiple}
pitching <- pitching %>%
  group_by(yearID, lgID) %>%
  mutate(z_era_year_lg = standardize(ERA),
         count = n())
```

When we arrange by the ERA standardized within the year and league, we now see that Pedro Martinez's 1999 and 2000 season with the Red Sox were even better than Dutch Leonard's 1914 season! 

```{r arrange year lg}
pitching %>%
  arrange(z_era_year_lg)
```

As a final note, when we group by multiple variables, the order in which we specify the variables in `group_by()` matters.


## Back to the figure

We started this module with a figure similar to one from Professor Wyner's class that plotted ERAs over time. When we previously ran the following code, we got a plot that's very similar to the desired one but that is missing the red line showing the average ERA within each season. 

```{r plot pitching, eval = FALSE}
ggplot(pitching) +
  geom_point(aes(x = yearID, y = ERA), size = 0.3)
```

To add the red line to our plot, we need to simply re-run the code above but with some additional calls to `geom_line`.

```{r plot pitching line}
ggplot(pitching) +
  geom_point(aes(x = yearID, y = ERA), size = 0.3) +
  ylim(0, 10) + 
  geom_line(data = pitching_summary, 
            aes(x = yearID, y = mean), col = 'red')
```

You'll notice that the last line of code is a bit different than anything we've seen before. In particular, we are specifying both the data and mapping within the same ggplot2 function. If all of the information we want to include in the plot is coming from the same data source, it's enough to just specify the `data` argument in the first line, like we do with `ggplot(data = pitching)` and not in every subsequent call to functions like `geom_point` or `geom_line`. However, whenever we want to add layers to a plot using data from another source (in this case, using data from `pitching_summary` to plot the average ERAs), we need to tell R explicitly and specify the data argument in `geom_line`.