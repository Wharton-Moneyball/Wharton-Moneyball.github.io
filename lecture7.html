<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Lecture 7: More About Regression</title>

<script src="site_libs/header-attrs-2.14/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/darkly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>










<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"><img id="logo" style="width: 200px;" src="figures/WMA_logo.png" /></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
    Home
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-sign-in"></span>
     
    Get Started
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="lecture0.html">Lecture 0</a>
    </li>
    <li>
      <a href="ps0.html">Problem Set 0</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-institution"></span>
     
    Academy
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="lecture1.html">Lecture 1</a>
    </li>
    <li>
      <a href="lecture2.html">Lecture 2</a>
    </li>
    <li>
      <a href="lecture3.html">Lecture 3</a>
    </li>
    <li>
      <a href="lecture4.html">Lecture 4</a>
    </li>
    <li>
      <a href="lecture5.html">Lecture 5</a>
    </li>
    <li>
      <a href="lecture6.html">Lecture 6</a>
    </li>
    <li>
      <a href="lecture7.html">Lecture 7</a>
    </li>
    <li>
      <a href="lecture8.html">Lecture 8</a>
    </li>
    <li class="divider"></li>
    <li>
      <a href="ps1.html">Problem Set 1</a>
    </li>
    <li>
      <a href="ps2.html">Problem Set 2</a>
    </li>
    <li>
      <a href="ps3.html">Problem Set 3</a>
    </li>
    <li>
      <a href="ps4.html">Problem Set 4</a>
    </li>
    <li>
      <a href="ps5.html">Problem Set 5</a>
    </li>
    <li>
      <a href="ps6.html">Problem Set 6</a>
    </li>
    <li class="divider"></li>
    <li>
      <a href="lecture_nflscrapR.html">nflscrapR Lecture</a>
    </li>
    <li>
      <a href="psX.html">Problem Set X</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-dribbble"></span>
     
    Training Camp
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="tc_lecture1.html">Lecture 1</a>
    </li>
    <li>
      <a href="tc_lecture2.html">Lecture 2</a>
    </li>
    <li>
      <a href="tc_lecture3.html">Lecture 3</a>
    </li>
    <li>
      <a href="tc_lecture4.html">Lecture 4</a>
    </li>
    <li>
      <a href="tc_lecture5.html">Lecture 5</a>
    </li>
    <li class="divider"></li>
    <li>
      <a href="tc_ps1.html">Problem Set 1</a>
    </li>
    <li>
      <a href="tc_ps2.html">Problem Set 2</a>
    </li>
    <li>
      <a href="tc_ps3.html">Problem Set 3</a>
    </li>
    <li class="divider"></li>
    <li>
      <a href="tc_lecture_data_sources.html">Data Sources Lecture</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Lecture 7: More About Regression</h1>

</div>


<p>In <a href="lecture4.html">Lecture 4</a> and <a
href="lecture6.html">Lecture 6</a>, we started building a model for
predicting a baseball player’s 2015 batting average using his 2014
batting average. We found that some models, even though they fit the
data quite well, appeared to <em>overfit</em> and may not predict future
observations well. Overfitting happens when the model is too complex;
the model is improperly describing the random error rather than properly
describing the relationship between variables. We will switch gears a
little bit and discuss how to diagnose overfit issues using data on
field goals in the NFL.</p>
<div id="training-and-testing-paradigm" class="section level2">
<h2>Training and Testing Paradigm</h2>
<p>Suppose we have fit multiple models to a given dataset. How should we
choose which model is the best?<br />
l One strategy might be to see how well the models predict the data we
used to fit them. While this seems intuitive, it is possible to
“over-learn” the patterns in this training data. Over-learning leads
models to apply only the sample with which it was built, not the overall
population or future data instances</p>
<p>A common alternative is to split our original dataset into two parts:
a <em>training</em> set and a <em>testing</em> set. We fit all of our
models on the training set and then see how well they predict the values
in the testing set. Think of the training set as a sample and the
testing set as a population.
<!-- need to include more descriptions here --></p>
</div>
<div id="field-goal-success-in-the-nfl" class="section level2">
<h2>Field Goal Success in the NFL</h2>
<p>The file “nfl_fg_train.csv” contains a large dataset about field
goals attempted in the NFL between 2005 and 2015. First, we will train
several models of field goal success with this data. Then, we will
evaluate their predictive performance using the data contained in
“nfl_fg_test.csv”.</p>
<p>The simplest forecast for field goal success probability is the
overall average success rate. This forecast does not differentiate
between players or attempt to adjust for distance or other game
contexts. To compute this forecast, we need to find the average of the
data in the column “Success.” The code below adds a column to the tbl
called “phat_all”</p>
<p>It turns out that kickers make just over 83% of their attempts.
However, we know that there are some truly elite kickers (e.g. Justin
Tucker) who make well over 83% of their attempts, and other kickers
(e.g. Billy Cundiff) who make less than 83% of their attempts. Instead
of forecasting field goal success probabilities with the overall
average, we could compute each individual kicker’s conversion rate. This
can be done using <code>group_by()</code> and <code>mutate()</code>. In
the code below, we add a column to <code>fg_train</code> called
“phat_kicker”, which contains each kicker’s individual field goal
conversion rate. Notice that because we adding a grouping to carry out
this computation, we need to remove the grouping using
<code>ungroup()</code> when we’re done.</p>
<p>Intuitively, distance is one of the main factors of whether a kicker
makes a field goal. We will use the <code>cut()</code> function to bin
the data according to distance. Then, we will compute the conversion
rate (averaged over all kickers) within each bin. To do this properly,
we must have used the <code>ungroup()</code> function at the end of our
last line of code.</p>
<p>In our dataset, the shortest field goal attempt was 18 yards and the
longest was 76. We will begin by binning our data into 10 yard
increments, 10 – 20, 20 – 30, …, 70 – 80. We then save the bin label in
a column called “Dist_10” and the predictions in a column called
“phat_dist_10”.</p>
<p>We can now look at a scatter plot of distance and our forecasts
“phat_dist_10”. Since there are many attempts from certain yardages,
we’ll use alpha-blending (see <a href="lecture2.html">Lecture 2</a> for
a refresher on this!) to change change the transparency of the points
according to their frequency. Essentially, darker dots have higher n
values than lighter dots.</p>
<p>It certainly looks like our predictions make some intuitive sense:
the estimated probability of making a field goal decreases as the
distance increases.</p>
<p>We also could have binned field goal Distance 5- or 2-yard
increments, saving bin labels into columns called “Dist_5” or “Dist_2”.
And similar to the 10-yard bins, we could add columns to
<code>fg_train</code> that computes the overall conversion rate within
each of these 5-yard or 2-yard bins.</p>
<p>Now we plot our predictions based on three different binning
methods.</p>
<p>Now when we binned our data into 2-yard increments, we find that our
forecasts are no longer monotonic decreasing. Probability of making a
field decreases overall; but in our 2-yard bins, the probability
increases from 44 to 46 and 52 to 54 years. Remember, monotonic means
only decreasing or only increasing for all values. In <a
href="lecture8.html">Lecture 8</a>, we’ll address this with a more
formal regression method.</p>
</div>
<div id="assessing-predictions" class="section level2">
<h2>Assessing Predictions</h2>
<p>We now have several predictive models of field goal success:
phat_all, phat_kicker, phat_dist_10, phat_dist_5, and phat_dist_2.
Recall from <a href="lecture4.html">Lecture 4</a> that to assess how
well we are predicting a continuous outcome, we could use the RMSE. When
predicting a binary outcome, we have a few more options. To set the
stage, let <span class="math inline">\(y_{i}\)</span> be the outcome of
the <span class="math inline">\(i^{\text{th}}\)</span> observation and
let <span class="math inline">\(\hat{p}_{i}\)</span> be the forecasted
probability that <span class="math inline">\(y_{i} = 1.\)</span>
(i.e. of making the FG)</p>
<p>The <a href="https://en.wikipedia.org/wiki/Brier_score">Brier
Score</a> is defined as <span class="math display">\[
BS = \frac{1}{n}\sum_{i = 1}^{n}{(y_{i} - \hat{p}_{i})^{2}}
\]</span> Looking at the formula, we see that the Brier score is just
the mean square error of our forecasts. Using code that is very nearly
identical to that used to compute RSME in <a
href="lecture4.html">Lecture 4</a>, we can compute the Brier score of
each of our prediction models.</p>
<p>Which model has the lowest Brier score? Do you think this model
over-fits the data?</p>
<p>Before assessing how well our models predict <em>out-of-sample</em>,
it will be useful to create tibbles that summarize each model’s
forecasts. For instance, when we grouped the data by kickers, we don’t
need multiple rows recording the same prediction for each kicker.
Instead, we can create a tbl called <code>phat_kicker</code> which has
one row per kicker and two columns, one identifying kicker and one for
the associated forecast:</p>
<p>Create similar tibbles for phat_dist_10, phat_dist_5, and
phat_dist_2.</p>
<p>The file “nfl_fg_test.csv” contains additional data on more field
goals kicked between 2005 and 2015. Since we have not used the data in
this file to train our models, we can get a sense of the
<em>out-of-sample</em> predictive performance of our models by looking
at how well they predict these field goals. We first load the data into
a tbl called <code>fg_test</code>.</p>
<p>Using <code>mutate()</code> and <code>cut()</code>, add columns
“Dist_10”, “Dist_5”, and “Dist_2” to <code>fg_test</code> that bin the
data into 10-yard, 5-yard, and 2-yard increments.</p>
<p>We are now ready to apply our <code>fg_train</code> model’s forecasts
to <code>fg_test</code>. For instance, we can add the forecast from
“phat_all”, which is just the overall conversion rate averaged over all
kickers. Notice that instead of computing the mean of the column
“Success” from <code>fg_test</code>, we are computing the mean from
<code>fg_train</code>.</p>
<p>Joining is a powerful technique to combine data from two different
tables based on a <em>key</em>. The key is what enables us to match rows
between the tables. For instance, to add the forecasts from the tbl
<code>phat_kicker</code> to the tbl <code>fg_test</code> join works
row-by-row. First, for each field goal in <code>fg_test</code>, the
function identifies the kicker who attempted the field goal. Then it
matches the with corresponding kicker row from the tbl
<code>phat_kicker</code>. The join function then appends that kicker’s
forecast from <code>phat_kicker</code> to the row in
<code>fg_test.</code> What we have just described is what is known as an
“inner join”. In this situation, the key was the Kicker. The code to
carry out these operations is given below.</p>
<p>To verify that we have successfully performed this join, we can print
out a few rows of <code>fg_test</code>:</p>
<p>Let’s unpack the inner join code line-by-line: in the first two
lines, we are telling R that we want to over-write <code>fg_test</code>.
Next, we pipe <code>fg_test</code> to the function
<code>inner_join</code>, which takes two more arguments. The first
argument <code>phat_kicker</code> tells the function where the
additional data corresponding to each key value is. The last argument
<code>by = "Kicker"</code> tells the function that the key we want to
use is the kicker.</p>
<p>Mimic the code above, we can add columns for <code>fg_test</code> for
the remaining three predictive models: <code>phat_dist_10</code>,
<code>phat_dist_5</code>, and <code>phat_dist_2</code>.</p>
<p>Now, we can compute the out-of-sample Brier scores for each of our
models. Which has the best out-of-sample performance?</p>
</div>
<div id="looking-ahead-to-tomorrow" class="section level2">
<h2>Looking ahead to tomorrow</h2>
<p>Tomorrow, we are going to use <em>logistic regression</em> to take
the “binning-and-averaging” approach we used above to its logical
extreme (i.e. what would happen if we made our bins infinitesimally
small). In order to do that, we will want to save our tbls
<code>fg_train</code> and <code>fg_test</code>:</p>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("show" === "show");
});
</script>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
